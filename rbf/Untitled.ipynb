{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   variace  skewness  curtosis  entropy  class\n0  3.62160    8.6661   -2.8073 -0.44699      0\n1  4.54590    8.1674   -2.4586 -1.46210      0\n2  3.86600   -2.6383    1.9242  0.10645      0\n3  3.45660    9.5228   -4.0112 -3.59440      0\n4  0.32924   -4.4552    4.5718 -0.98880      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variace</th>\n      <th>skewness</th>\n      <th>curtosis</th>\n      <th>entropy</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rbf.rbflayer import InitCentersKMeans, RBFLayer\n",
    "df = pd.read_csv(r'banknotes.txt',sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.drop('class',axis=1),df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "initializer = InitCentersKMeans(X_train)\n",
    "rbflayer = RBFLayer(10,\n",
    "                    initializer=InitCentersKMeans(X_train),\n",
    "                    betas=2.0,\n",
    "                    input_shape=(1,))\n",
    "outputlayer = Dense(2, activation=\"softmax\")\n",
    "input_ = Input(shape=X_train.shape[1:])\n",
    "\n",
    "model.add(input_)\n",
    "model.add(rbflayer)\n",
    "model.add(outputlayer)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "11/11 - 0s - loss: 0.6915 - accuracy: 0.5598\n",
      "Epoch 2/300\n",
      "11/11 - 0s - loss: 0.6905 - accuracy: 0.5520\n",
      "Epoch 3/300\n",
      "11/11 - 0s - loss: 0.6894 - accuracy: 0.5520\n",
      "Epoch 4/300\n",
      "11/11 - 0s - loss: 0.6885 - accuracy: 0.5559\n",
      "Epoch 5/300\n",
      "11/11 - 0s - loss: 0.6876 - accuracy: 0.5578\n",
      "Epoch 6/300\n",
      "11/11 - 0s - loss: 0.6870 - accuracy: 0.5598\n",
      "Epoch 7/300\n",
      "11/11 - 0s - loss: 0.6862 - accuracy: 0.5607\n",
      "Epoch 8/300\n",
      "11/11 - 0s - loss: 0.6857 - accuracy: 0.5607\n",
      "Epoch 9/300\n",
      "11/11 - 0s - loss: 0.6852 - accuracy: 0.5607\n",
      "Epoch 10/300\n",
      "11/11 - 0s - loss: 0.6847 - accuracy: 0.5607\n",
      "Epoch 11/300\n",
      "11/11 - 0s - loss: 0.6843 - accuracy: 0.5607\n",
      "Epoch 12/300\n",
      "11/11 - 0s - loss: 0.6840 - accuracy: 0.5607\n",
      "Epoch 13/300\n",
      "11/11 - 0s - loss: 0.6836 - accuracy: 0.5607\n",
      "Epoch 14/300\n",
      "11/11 - 0s - loss: 0.6833 - accuracy: 0.5607\n",
      "Epoch 15/300\n",
      "11/11 - 0s - loss: 0.6829 - accuracy: 0.5607\n",
      "Epoch 16/300\n",
      "11/11 - 0s - loss: 0.6826 - accuracy: 0.5607\n",
      "Epoch 17/300\n",
      "11/11 - 0s - loss: 0.6823 - accuracy: 0.5607\n",
      "Epoch 18/300\n",
      "11/11 - 0s - loss: 0.6820 - accuracy: 0.5607\n",
      "Epoch 19/300\n",
      "11/11 - 0s - loss: 0.6818 - accuracy: 0.5607\n",
      "Epoch 20/300\n",
      "11/11 - 0s - loss: 0.6815 - accuracy: 0.5607\n",
      "Epoch 21/300\n",
      "11/11 - 0s - loss: 0.6812 - accuracy: 0.5607\n",
      "Epoch 22/300\n",
      "11/11 - 0s - loss: 0.6809 - accuracy: 0.5617\n",
      "Epoch 23/300\n",
      "11/11 - 0s - loss: 0.6806 - accuracy: 0.5617\n",
      "Epoch 24/300\n",
      "11/11 - 0s - loss: 0.6803 - accuracy: 0.5627\n",
      "Epoch 25/300\n",
      "11/11 - 0s - loss: 0.6799 - accuracy: 0.5637\n",
      "Epoch 26/300\n",
      "11/11 - 0s - loss: 0.6796 - accuracy: 0.5637\n",
      "Epoch 27/300\n",
      "11/11 - 0s - loss: 0.6793 - accuracy: 0.5637\n",
      "Epoch 28/300\n",
      "11/11 - 0s - loss: 0.6789 - accuracy: 0.5637\n",
      "Epoch 29/300\n",
      "11/11 - 0s - loss: 0.6786 - accuracy: 0.5637\n",
      "Epoch 30/300\n",
      "11/11 - 0s - loss: 0.6782 - accuracy: 0.5637\n",
      "Epoch 31/300\n",
      "11/11 - 0s - loss: 0.6778 - accuracy: 0.5637\n",
      "Epoch 32/300\n",
      "11/11 - 0s - loss: 0.6774 - accuracy: 0.5637\n",
      "Epoch 33/300\n",
      "11/11 - 0s - loss: 0.6770 - accuracy: 0.5656\n",
      "Epoch 34/300\n",
      "11/11 - 0s - loss: 0.6765 - accuracy: 0.5675\n",
      "Epoch 35/300\n",
      "11/11 - 0s - loss: 0.6760 - accuracy: 0.5685\n",
      "Epoch 36/300\n",
      "11/11 - 0s - loss: 0.6755 - accuracy: 0.5685\n",
      "Epoch 37/300\n",
      "11/11 - 0s - loss: 0.6749 - accuracy: 0.5695\n",
      "Epoch 38/300\n",
      "11/11 - 0s - loss: 0.6743 - accuracy: 0.5695\n",
      "Epoch 39/300\n",
      "11/11 - 0s - loss: 0.6737 - accuracy: 0.5734\n",
      "Epoch 40/300\n",
      "11/11 - 0s - loss: 0.6731 - accuracy: 0.5753\n",
      "Epoch 41/300\n",
      "11/11 - 0s - loss: 0.6724 - accuracy: 0.5763\n",
      "Epoch 42/300\n",
      "11/11 - 0s - loss: 0.6717 - accuracy: 0.5792\n",
      "Epoch 43/300\n",
      "11/11 - 0s - loss: 0.6710 - accuracy: 0.5841\n",
      "Epoch 44/300\n",
      "11/11 - 0s - loss: 0.6701 - accuracy: 0.5841\n",
      "Epoch 45/300\n",
      "11/11 - 0s - loss: 0.6693 - accuracy: 0.5870\n",
      "Epoch 46/300\n",
      "11/11 - 0s - loss: 0.6685 - accuracy: 0.5879\n",
      "Epoch 47/300\n",
      "11/11 - 0s - loss: 0.6676 - accuracy: 0.5899\n",
      "Epoch 48/300\n",
      "11/11 - 0s - loss: 0.6666 - accuracy: 0.5899\n",
      "Epoch 49/300\n",
      "11/11 - 0s - loss: 0.6657 - accuracy: 0.5928\n",
      "Epoch 50/300\n",
      "11/11 - 0s - loss: 0.6647 - accuracy: 0.5948\n",
      "Epoch 51/300\n",
      "11/11 - 0s - loss: 0.6635 - accuracy: 0.5957\n",
      "Epoch 52/300\n",
      "11/11 - 0s - loss: 0.6624 - accuracy: 0.5986\n",
      "Epoch 53/300\n",
      "11/11 - 0s - loss: 0.6613 - accuracy: 0.5986\n",
      "Epoch 54/300\n",
      "11/11 - 0s - loss: 0.6601 - accuracy: 0.6006\n",
      "Epoch 55/300\n",
      "11/11 - 0s - loss: 0.6589 - accuracy: 0.6006\n",
      "Epoch 56/300\n",
      "11/11 - 0s - loss: 0.6575 - accuracy: 0.6045\n",
      "Epoch 57/300\n",
      "11/11 - 0s - loss: 0.6561 - accuracy: 0.6054\n",
      "Epoch 58/300\n",
      "11/11 - 0s - loss: 0.6547 - accuracy: 0.6084\n",
      "Epoch 59/300\n",
      "11/11 - 0s - loss: 0.6533 - accuracy: 0.6113\n",
      "Epoch 60/300\n",
      "11/11 - 0s - loss: 0.6517 - accuracy: 0.6113\n",
      "Epoch 61/300\n",
      "11/11 - 0s - loss: 0.6501 - accuracy: 0.6132\n",
      "Epoch 62/300\n",
      "11/11 - 0s - loss: 0.6485 - accuracy: 0.6152\n",
      "Epoch 63/300\n",
      "11/11 - 0s - loss: 0.6468 - accuracy: 0.6181\n",
      "Epoch 64/300\n",
      "11/11 - 0s - loss: 0.6450 - accuracy: 0.6210\n",
      "Epoch 65/300\n",
      "11/11 - 0s - loss: 0.6432 - accuracy: 0.6220\n",
      "Epoch 66/300\n",
      "11/11 - 0s - loss: 0.6413 - accuracy: 0.6249\n",
      "Epoch 67/300\n",
      "11/11 - 0s - loss: 0.6394 - accuracy: 0.6268\n",
      "Epoch 68/300\n",
      "11/11 - 0s - loss: 0.6374 - accuracy: 0.6297\n",
      "Epoch 69/300\n",
      "11/11 - 0s - loss: 0.6353 - accuracy: 0.6307\n",
      "Epoch 70/300\n",
      "11/11 - 0s - loss: 0.6330 - accuracy: 0.6365\n",
      "Epoch 71/300\n",
      "11/11 - 0s - loss: 0.6307 - accuracy: 0.6385\n",
      "Epoch 72/300\n",
      "11/11 - 0s - loss: 0.6282 - accuracy: 0.6404\n",
      "Epoch 73/300\n",
      "11/11 - 0s - loss: 0.6256 - accuracy: 0.6443\n",
      "Epoch 74/300\n",
      "11/11 - 0s - loss: 0.6228 - accuracy: 0.6472\n",
      "Epoch 75/300\n",
      "11/11 - 0s - loss: 0.6199 - accuracy: 0.6511\n",
      "Epoch 76/300\n",
      "11/11 - 0s - loss: 0.6169 - accuracy: 0.6540\n",
      "Epoch 77/300\n",
      "11/11 - 0s - loss: 0.6135 - accuracy: 0.6560\n",
      "Epoch 78/300\n",
      "11/11 - 0s - loss: 0.6100 - accuracy: 0.6579\n",
      "Epoch 79/300\n",
      "11/11 - 0s - loss: 0.6063 - accuracy: 0.6628\n",
      "Epoch 80/300\n",
      "11/11 - 0s - loss: 0.6024 - accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "11/11 - 0s - loss: 0.5980 - accuracy: 0.6715\n",
      "Epoch 82/300\n",
      "11/11 - 0s - loss: 0.5933 - accuracy: 0.6783\n",
      "Epoch 83/300\n",
      "11/11 - 0s - loss: 0.5880 - accuracy: 0.6822\n",
      "Epoch 84/300\n",
      "11/11 - 0s - loss: 0.5822 - accuracy: 0.6919\n",
      "Epoch 85/300\n",
      "11/11 - 0s - loss: 0.5758 - accuracy: 0.7007\n",
      "Epoch 86/300\n",
      "11/11 - 0s - loss: 0.5682 - accuracy: 0.7085\n",
      "Epoch 87/300\n",
      "11/11 - 0s - loss: 0.5596 - accuracy: 0.7211\n",
      "Epoch 88/300\n",
      "11/11 - 0s - loss: 0.5496 - accuracy: 0.7396\n",
      "Epoch 89/300\n",
      "11/11 - 0s - loss: 0.5368 - accuracy: 0.7561\n",
      "Epoch 90/300\n",
      "11/11 - 0s - loss: 0.5214 - accuracy: 0.7619\n",
      "Epoch 91/300\n",
      "11/11 - 0s - loss: 0.5016 - accuracy: 0.7843\n",
      "Epoch 92/300\n",
      "11/11 - 0s - loss: 0.4788 - accuracy: 0.7988\n",
      "Epoch 93/300\n",
      "11/11 - 0s - loss: 0.4602 - accuracy: 0.8056\n",
      "Epoch 94/300\n",
      "11/11 - 0s - loss: 0.4386 - accuracy: 0.8115\n",
      "Epoch 95/300\n",
      "11/11 - 0s - loss: 0.4084 - accuracy: 0.8105\n",
      "Epoch 96/300\n",
      "11/11 - 0s - loss: 0.3790 - accuracy: 0.7901\n",
      "Epoch 97/300\n",
      "11/11 - 0s - loss: 0.3718 - accuracy: 0.8144\n",
      "Epoch 98/300\n",
      "11/11 - 0s - loss: 0.3609 - accuracy: 0.8066\n",
      "Epoch 99/300\n",
      "11/11 - 0s - loss: 0.3522 - accuracy: 0.8115\n",
      "Epoch 100/300\n",
      "11/11 - 0s - loss: 0.3453 - accuracy: 0.8027\n",
      "Epoch 101/300\n",
      "11/11 - 0s - loss: 0.3342 - accuracy: 0.8056\n",
      "Epoch 102/300\n",
      "11/11 - 0s - loss: 0.3259 - accuracy: 0.8124\n",
      "Epoch 103/300\n",
      "11/11 - 0s - loss: 0.3196 - accuracy: 0.8124\n",
      "Epoch 104/300\n",
      "11/11 - 0s - loss: 0.3146 - accuracy: 0.8115\n",
      "Epoch 105/300\n",
      "11/11 - 0s - loss: 0.3092 - accuracy: 0.8086\n",
      "Epoch 106/300\n",
      "11/11 - 0s - loss: 0.3062 - accuracy: 0.8183\n",
      "Epoch 107/300\n",
      "11/11 - 0s - loss: 0.2996 - accuracy: 0.8144\n",
      "Epoch 108/300\n",
      "11/11 - 0s - loss: 0.2958 - accuracy: 0.8183\n",
      "Epoch 109/300\n",
      "11/11 - 0s - loss: 0.2930 - accuracy: 0.8319\n",
      "Epoch 110/300\n",
      "11/11 - 0s - loss: 0.2877 - accuracy: 0.8192\n",
      "Epoch 111/300\n",
      "11/11 - 0s - loss: 0.2863 - accuracy: 0.8513\n",
      "Epoch 112/300\n",
      "11/11 - 0s - loss: 0.2796 - accuracy: 0.8319\n",
      "Epoch 113/300\n",
      "11/11 - 0s - loss: 0.2741 - accuracy: 0.8484\n",
      "Epoch 114/300\n",
      "11/11 - 0s - loss: 0.2697 - accuracy: 0.8844\n",
      "Epoch 115/300\n",
      "11/11 - 0s - loss: 0.2644 - accuracy: 0.8931\n",
      "Epoch 116/300\n",
      "11/11 - 0s - loss: 0.2611 - accuracy: 0.9417\n",
      "Epoch 117/300\n",
      "11/11 - 0s - loss: 0.2523 - accuracy: 0.8989\n",
      "Epoch 118/300\n",
      "11/11 - 0s - loss: 0.2433 - accuracy: 0.9427\n",
      "Epoch 119/300\n",
      "11/11 - 0s - loss: 0.2400 - accuracy: 0.9456\n",
      "Epoch 120/300\n",
      "11/11 - 0s - loss: 0.2370 - accuracy: 0.9485\n",
      "Epoch 121/300\n",
      "11/11 - 0s - loss: 0.2360 - accuracy: 0.9534\n",
      "Epoch 122/300\n",
      "11/11 - 0s - loss: 0.2342 - accuracy: 0.9466\n",
      "Epoch 123/300\n",
      "11/11 - 0s - loss: 0.2295 - accuracy: 0.9534\n",
      "Epoch 124/300\n",
      "11/11 - 0s - loss: 0.2266 - accuracy: 0.9524\n",
      "Epoch 125/300\n",
      "11/11 - 0s - loss: 0.2235 - accuracy: 0.9534\n",
      "Epoch 126/300\n",
      "11/11 - 0s - loss: 0.2204 - accuracy: 0.9553\n",
      "Epoch 127/300\n",
      "11/11 - 0s - loss: 0.2174 - accuracy: 0.9582\n",
      "Epoch 128/300\n",
      "11/11 - 0s - loss: 0.2148 - accuracy: 0.9534\n",
      "Epoch 129/300\n",
      "11/11 - 0s - loss: 0.2107 - accuracy: 0.9621\n",
      "Epoch 130/300\n",
      "11/11 - 0s - loss: 0.2075 - accuracy: 0.9611\n",
      "Epoch 131/300\n",
      "11/11 - 0s - loss: 0.2024 - accuracy: 0.9621\n",
      "Epoch 132/300\n",
      "11/11 - 0s - loss: 0.1976 - accuracy: 0.9640\n",
      "Epoch 133/300\n",
      "11/11 - 0s - loss: 0.1915 - accuracy: 0.9660\n",
      "Epoch 134/300\n",
      "11/11 - 0s - loss: 0.1840 - accuracy: 0.9650\n",
      "Epoch 135/300\n",
      "11/11 - 0s - loss: 0.1755 - accuracy: 0.9776\n",
      "Epoch 136/300\n",
      "11/11 - 0s - loss: 0.1734 - accuracy: 0.9747\n",
      "Epoch 137/300\n",
      "11/11 - 0s - loss: 0.1670 - accuracy: 0.9776\n",
      "Epoch 138/300\n",
      "11/11 - 0s - loss: 0.1613 - accuracy: 0.9815\n",
      "Epoch 139/300\n",
      "11/11 - 0s - loss: 0.1542 - accuracy: 0.9835\n",
      "Epoch 140/300\n",
      "11/11 - 0s - loss: 0.1495 - accuracy: 0.9796\n",
      "Epoch 141/300\n",
      "11/11 - 0s - loss: 0.1478 - accuracy: 0.9806\n",
      "Epoch 142/300\n",
      "11/11 - 0s - loss: 0.1455 - accuracy: 0.9757\n",
      "Epoch 143/300\n",
      "11/11 - 0s - loss: 0.1430 - accuracy: 0.9796\n",
      "Epoch 144/300\n",
      "11/11 - 0s - loss: 0.1419 - accuracy: 0.9825\n",
      "Epoch 145/300\n",
      "11/11 - 0s - loss: 0.1402 - accuracy: 0.9835\n",
      "Epoch 146/300\n",
      "11/11 - 0s - loss: 0.1385 - accuracy: 0.9806\n",
      "Epoch 147/300\n",
      "11/11 - 0s - loss: 0.1366 - accuracy: 0.9806\n",
      "Epoch 148/300\n",
      "11/11 - 0s - loss: 0.1346 - accuracy: 0.9854\n",
      "Epoch 149/300\n",
      "11/11 - 0s - loss: 0.1335 - accuracy: 0.9825\n",
      "Epoch 150/300\n",
      "11/11 - 0s - loss: 0.1350 - accuracy: 0.9786\n",
      "Epoch 151/300\n",
      "11/11 - 0s - loss: 0.1312 - accuracy: 0.9864\n",
      "Epoch 152/300\n",
      "11/11 - 0s - loss: 0.1294 - accuracy: 0.9815\n",
      "Epoch 153/300\n",
      "11/11 - 0s - loss: 0.1282 - accuracy: 0.9835\n",
      "Epoch 154/300\n",
      "11/11 - 0s - loss: 0.1236 - accuracy: 0.9864\n",
      "Epoch 155/300\n",
      "11/11 - 0s - loss: 0.1196 - accuracy: 0.9835\n",
      "Epoch 156/300\n",
      "11/11 - 0s - loss: 0.1200 - accuracy: 0.9864\n",
      "Epoch 157/300\n",
      "11/11 - 0s - loss: 0.1183 - accuracy: 0.9874\n",
      "Epoch 158/300\n",
      "11/11 - 0s - loss: 0.1171 - accuracy: 0.9864\n",
      "Epoch 159/300\n",
      "11/11 - 0s - loss: 0.1162 - accuracy: 0.9835\n",
      "Epoch 160/300\n",
      "11/11 - 0s - loss: 0.1142 - accuracy: 0.9874\n",
      "Epoch 161/300\n",
      "11/11 - 0s - loss: 0.1130 - accuracy: 0.9825\n",
      "Epoch 162/300\n",
      "11/11 - 0s - loss: 0.1119 - accuracy: 0.9864\n",
      "Epoch 163/300\n",
      "11/11 - 0s - loss: 0.1109 - accuracy: 0.9883\n",
      "Epoch 164/300\n",
      "11/11 - 0s - loss: 0.1109 - accuracy: 0.9845\n",
      "Epoch 165/300\n",
      "11/11 - 0s - loss: 0.1089 - accuracy: 0.9874\n",
      "Epoch 166/300\n",
      "11/11 - 0s - loss: 0.1084 - accuracy: 0.9883\n",
      "Epoch 167/300\n",
      "11/11 - 0s - loss: 0.1069 - accuracy: 0.9883\n",
      "Epoch 168/300\n",
      "11/11 - 0s - loss: 0.1066 - accuracy: 0.9874\n",
      "Epoch 169/300\n",
      "11/11 - 0s - loss: 0.1054 - accuracy: 0.9883\n",
      "Epoch 170/300\n",
      "11/11 - 0s - loss: 0.1059 - accuracy: 0.9883\n",
      "Epoch 171/300\n",
      "11/11 - 0s - loss: 0.1047 - accuracy: 0.9883\n",
      "Epoch 172/300\n",
      "11/11 - 0s - loss: 0.1052 - accuracy: 0.9835\n",
      "Epoch 173/300\n",
      "11/11 - 0s - loss: 0.1033 - accuracy: 0.9874\n",
      "Epoch 174/300\n",
      "11/11 - 0s - loss: 0.1025 - accuracy: 0.9864\n",
      "Epoch 175/300\n",
      "11/11 - 0s - loss: 0.1007 - accuracy: 0.9883\n",
      "Epoch 176/300\n",
      "11/11 - 0s - loss: 0.1007 - accuracy: 0.9893\n",
      "Epoch 177/300\n",
      "11/11 - 0s - loss: 0.1016 - accuracy: 0.9874\n",
      "Epoch 178/300\n",
      "11/11 - 0s - loss: 0.0979 - accuracy: 0.9883\n",
      "Epoch 179/300\n",
      "11/11 - 0s - loss: 0.0994 - accuracy: 0.9893\n",
      "Epoch 180/300\n",
      "11/11 - 0s - loss: 0.0973 - accuracy: 0.9893\n",
      "Epoch 181/300\n",
      "11/11 - 0s - loss: 0.0962 - accuracy: 0.9883\n",
      "Epoch 182/300\n",
      "11/11 - 0s - loss: 0.0962 - accuracy: 0.9883\n",
      "Epoch 183/300\n",
      "11/11 - 0s - loss: 0.0964 - accuracy: 0.9874\n",
      "Epoch 184/300\n",
      "11/11 - 0s - loss: 0.0974 - accuracy: 0.9913\n",
      "Epoch 185/300\n",
      "11/11 - 0s - loss: 0.0960 - accuracy: 0.9883\n",
      "Epoch 186/300\n",
      "11/11 - 0s - loss: 0.0930 - accuracy: 0.9883\n",
      "Epoch 187/300\n",
      "11/11 - 0s - loss: 0.0935 - accuracy: 0.9893\n",
      "Epoch 188/300\n",
      "11/11 - 0s - loss: 0.0919 - accuracy: 0.9883\n",
      "Epoch 189/300\n",
      "11/11 - 0s - loss: 0.0918 - accuracy: 0.9893\n",
      "Epoch 190/300\n",
      "11/11 - 0s - loss: 0.0923 - accuracy: 0.9883\n",
      "Epoch 191/300\n",
      "11/11 - 0s - loss: 0.0904 - accuracy: 0.9883\n",
      "Epoch 192/300\n",
      "11/11 - 0s - loss: 0.0906 - accuracy: 0.9893\n",
      "Epoch 193/300\n",
      "11/11 - 0s - loss: 0.0918 - accuracy: 0.9883\n",
      "Epoch 194/300\n",
      "11/11 - 0s - loss: 0.0881 - accuracy: 0.9883\n",
      "Epoch 195/300\n",
      "11/11 - 0s - loss: 0.0888 - accuracy: 0.9883\n",
      "Epoch 196/300\n",
      "11/11 - 0s - loss: 0.0884 - accuracy: 0.9893\n",
      "Epoch 197/300\n",
      "11/11 - 0s - loss: 0.0870 - accuracy: 0.9893\n",
      "Epoch 198/300\n",
      "11/11 - 0s - loss: 0.0864 - accuracy: 0.9893\n",
      "Epoch 199/300\n",
      "11/11 - 0s - loss: 0.0860 - accuracy: 0.9883\n",
      "Epoch 200/300\n",
      "11/11 - 0s - loss: 0.0861 - accuracy: 0.9893\n",
      "Epoch 201/300\n",
      "11/11 - 0s - loss: 0.0847 - accuracy: 0.9883\n",
      "Epoch 202/300\n",
      "11/11 - 0s - loss: 0.0849 - accuracy: 0.9893\n",
      "Epoch 203/300\n",
      "11/11 - 0s - loss: 0.0840 - accuracy: 0.9893\n",
      "Epoch 204/300\n",
      "11/11 - 0s - loss: 0.0834 - accuracy: 0.9893\n",
      "Epoch 205/300\n",
      "11/11 - 0s - loss: 0.0828 - accuracy: 0.9893\n",
      "Epoch 206/300\n",
      "11/11 - 0s - loss: 0.0824 - accuracy: 0.9893\n",
      "Epoch 207/300\n",
      "11/11 - 0s - loss: 0.0818 - accuracy: 0.9893\n",
      "Epoch 208/300\n",
      "11/11 - 0s - loss: 0.0812 - accuracy: 0.9893\n",
      "Epoch 209/300\n",
      "11/11 - 0s - loss: 0.0810 - accuracy: 0.9893\n",
      "Epoch 210/300\n",
      "11/11 - 0s - loss: 0.0807 - accuracy: 0.9893\n",
      "Epoch 211/300\n",
      "11/11 - 0s - loss: 0.0808 - accuracy: 0.9893\n",
      "Epoch 212/300\n",
      "11/11 - 0s - loss: 0.0804 - accuracy: 0.9893\n",
      "Epoch 213/300\n",
      "11/11 - 0s - loss: 0.0796 - accuracy: 0.9893\n",
      "Epoch 214/300\n",
      "11/11 - 0s - loss: 0.0789 - accuracy: 0.9883\n",
      "Epoch 215/300\n",
      "11/11 - 0s - loss: 0.0775 - accuracy: 0.9893\n",
      "Epoch 216/300\n",
      "11/11 - 0s - loss: 0.0803 - accuracy: 0.9903\n",
      "Epoch 217/300\n",
      "11/11 - 0s - loss: 0.0764 - accuracy: 0.9893\n",
      "Epoch 218/300\n",
      "11/11 - 0s - loss: 0.0759 - accuracy: 0.9903\n",
      "Epoch 219/300\n",
      "11/11 - 0s - loss: 0.0755 - accuracy: 0.9893\n",
      "Epoch 220/300\n",
      "11/11 - 0s - loss: 0.0757 - accuracy: 0.9893\n",
      "Epoch 221/300\n",
      "11/11 - 0s - loss: 0.0741 - accuracy: 0.9893\n",
      "Epoch 222/300\n",
      "11/11 - 0s - loss: 0.0737 - accuracy: 0.9913\n",
      "Epoch 223/300\n",
      "11/11 - 0s - loss: 0.0726 - accuracy: 0.9893\n",
      "Epoch 224/300\n",
      "11/11 - 0s - loss: 0.0704 - accuracy: 0.9903\n",
      "Epoch 225/300\n",
      "11/11 - 0s - loss: 0.0679 - accuracy: 0.9903\n",
      "Epoch 226/300\n",
      "11/11 - 0s - loss: 0.0670 - accuracy: 0.9893\n",
      "Epoch 227/300\n",
      "11/11 - 0s - loss: 0.0665 - accuracy: 0.9903\n",
      "Epoch 228/300\n",
      "11/11 - 0s - loss: 0.0660 - accuracy: 0.9903\n",
      "Epoch 229/300\n",
      "11/11 - 0s - loss: 0.0663 - accuracy: 0.9903\n",
      "Epoch 230/300\n",
      "11/11 - 0s - loss: 0.0660 - accuracy: 0.9903\n",
      "Epoch 231/300\n",
      "11/11 - 0s - loss: 0.0646 - accuracy: 0.9903\n",
      "Epoch 232/300\n",
      "11/11 - 0s - loss: 0.0656 - accuracy: 0.9913\n",
      "Epoch 233/300\n",
      "11/11 - 0s - loss: 0.0657 - accuracy: 0.9893\n",
      "Epoch 234/300\n",
      "11/11 - 0s - loss: 0.0645 - accuracy: 0.9922\n",
      "Epoch 235/300\n",
      "11/11 - 0s - loss: 0.0635 - accuracy: 0.9893\n",
      "Epoch 236/300\n",
      "11/11 - 0s - loss: 0.0632 - accuracy: 0.9903\n",
      "Epoch 237/300\n",
      "11/11 - 0s - loss: 0.0627 - accuracy: 0.9913\n",
      "Epoch 238/300\n",
      "11/11 - 0s - loss: 0.0622 - accuracy: 0.9893\n",
      "Epoch 239/300\n",
      "11/11 - 0s - loss: 0.0611 - accuracy: 0.9913\n",
      "Epoch 240/300\n",
      "11/11 - 0s - loss: 0.0615 - accuracy: 0.9903\n",
      "Epoch 241/300\n",
      "11/11 - 0s - loss: 0.0599 - accuracy: 0.9932\n",
      "Epoch 242/300\n",
      "11/11 - 0s - loss: 0.0619 - accuracy: 0.9913\n",
      "Epoch 243/300\n",
      "11/11 - 0s - loss: 0.0601 - accuracy: 0.9903\n",
      "Epoch 244/300\n",
      "11/11 - 0s - loss: 0.0588 - accuracy: 0.9903\n",
      "Epoch 245/300\n",
      "11/11 - 0s - loss: 0.0588 - accuracy: 0.9903\n",
      "Epoch 246/300\n",
      "11/11 - 0s - loss: 0.0580 - accuracy: 0.9913\n",
      "Epoch 247/300\n",
      "11/11 - 0s - loss: 0.0578 - accuracy: 0.9903\n",
      "Epoch 248/300\n",
      "11/11 - 0s - loss: 0.0573 - accuracy: 0.9903\n",
      "Epoch 249/300\n",
      "11/11 - 0s - loss: 0.0563 - accuracy: 0.9903\n",
      "Epoch 250/300\n",
      "11/11 - 0s - loss: 0.0566 - accuracy: 0.9913\n",
      "Epoch 251/300\n",
      "11/11 - 0s - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 252/300\n",
      "11/11 - 0s - loss: 0.0556 - accuracy: 0.9922\n",
      "Epoch 253/300\n",
      "11/11 - 0s - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 254/300\n",
      "11/11 - 0s - loss: 0.0554 - accuracy: 0.9922\n",
      "Epoch 255/300\n",
      "11/11 - 0s - loss: 0.0547 - accuracy: 0.9913\n",
      "Epoch 256/300\n",
      "11/11 - 0s - loss: 0.0546 - accuracy: 0.9903\n",
      "Epoch 257/300\n",
      "11/11 - 0s - loss: 0.0547 - accuracy: 0.9932\n",
      "Epoch 258/300\n",
      "11/11 - 0s - loss: 0.0548 - accuracy: 0.9913\n",
      "Epoch 259/300\n",
      "11/11 - 0s - loss: 0.0534 - accuracy: 0.9922\n",
      "Epoch 260/300\n",
      "11/11 - 0s - loss: 0.0542 - accuracy: 0.9903\n",
      "Epoch 261/300\n",
      "11/11 - 0s - loss: 0.0555 - accuracy: 0.9971\n",
      "Epoch 262/300\n",
      "11/11 - 0s - loss: 0.0556 - accuracy: 0.9913\n",
      "Epoch 263/300\n",
      "11/11 - 0s - loss: 0.0561 - accuracy: 0.9951\n",
      "Epoch 264/300\n",
      "11/11 - 0s - loss: 0.0538 - accuracy: 0.9893\n",
      "Epoch 265/300\n",
      "11/11 - 0s - loss: 0.0539 - accuracy: 0.9951\n",
      "Epoch 266/300\n",
      "11/11 - 0s - loss: 0.0544 - accuracy: 0.9913\n",
      "Epoch 267/300\n",
      "11/11 - 0s - loss: 0.0525 - accuracy: 0.9951\n",
      "Epoch 268/300\n",
      "11/11 - 0s - loss: 0.0537 - accuracy: 0.9903\n",
      "Epoch 269/300\n",
      "11/11 - 0s - loss: 0.0520 - accuracy: 0.9942\n",
      "Epoch 270/300\n",
      "11/11 - 0s - loss: 0.0509 - accuracy: 0.9922\n",
      "Epoch 271/300\n",
      "11/11 - 0s - loss: 0.0507 - accuracy: 0.9922\n",
      "Epoch 272/300\n",
      "11/11 - 0s - loss: 0.0509 - accuracy: 0.9942\n",
      "Epoch 273/300\n",
      "11/11 - 0s - loss: 0.0500 - accuracy: 0.9922\n",
      "Epoch 274/300\n",
      "11/11 - 0s - loss: 0.0500 - accuracy: 0.9942\n",
      "Epoch 275/300\n",
      "11/11 - 0s - loss: 0.0498 - accuracy: 0.9913\n",
      "Epoch 276/300\n",
      "11/11 - 0s - loss: 0.0497 - accuracy: 0.9922\n",
      "Epoch 277/300\n",
      "11/11 - 0s - loss: 0.0491 - accuracy: 0.9942\n",
      "Epoch 278/300\n",
      "11/11 - 0s - loss: 0.0490 - accuracy: 0.9932\n",
      "Epoch 279/300\n",
      "11/11 - 0s - loss: 0.0492 - accuracy: 0.9922\n",
      "Epoch 280/300\n",
      "11/11 - 0s - loss: 0.0486 - accuracy: 0.9932\n",
      "Epoch 281/300\n",
      "11/11 - 0s - loss: 0.0484 - accuracy: 0.9903\n",
      "Epoch 282/300\n",
      "11/11 - 0s - loss: 0.0479 - accuracy: 0.9951\n",
      "Epoch 283/300\n",
      "11/11 - 0s - loss: 0.0481 - accuracy: 0.9922\n",
      "Epoch 284/300\n",
      "11/11 - 0s - loss: 0.0477 - accuracy: 0.9913\n",
      "Epoch 285/300\n",
      "11/11 - 0s - loss: 0.0481 - accuracy: 0.9913\n",
      "Epoch 286/300\n",
      "11/11 - 0s - loss: 0.0476 - accuracy: 0.9951\n",
      "Epoch 287/300\n",
      "11/11 - 0s - loss: 0.0475 - accuracy: 0.9913\n",
      "Epoch 288/300\n",
      "11/11 - 0s - loss: 0.0472 - accuracy: 0.9951\n",
      "Epoch 289/300\n",
      "11/11 - 0s - loss: 0.0469 - accuracy: 0.9942\n",
      "Epoch 290/300\n",
      "11/11 - 0s - loss: 0.0463 - accuracy: 0.9932\n",
      "Epoch 291/300\n",
      "11/11 - 0s - loss: 0.0466 - accuracy: 0.9951\n",
      "Epoch 292/300\n",
      "11/11 - 0s - loss: 0.0480 - accuracy: 0.9903\n",
      "Epoch 293/300\n",
      "11/11 - 0s - loss: 0.0478 - accuracy: 0.9942\n",
      "Epoch 294/300\n",
      "11/11 - 0s - loss: 0.0459 - accuracy: 0.9922\n",
      "Epoch 295/300\n",
      "11/11 - 0s - loss: 0.0461 - accuracy: 0.9922\n",
      "Epoch 296/300\n",
      "11/11 - 0s - loss: 0.0457 - accuracy: 0.9951\n",
      "Epoch 297/300\n",
      "11/11 - 0s - loss: 0.0457 - accuracy: 0.9922\n",
      "Epoch 298/300\n",
      "11/11 - 0s - loss: 0.0457 - accuracy: 0.9942\n",
      "Epoch 299/300\n",
      "11/11 - 0s - loss: 0.0454 - accuracy: 0.9922\n",
      "Epoch 300/300\n",
      "11/11 - 0s - loss: 0.0458 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x10879d710>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "              batch_size=100,\n",
    "              epochs=300,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 786us/step - loss: 0.0459 - accuracy: 0.9942\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.045903924852609634, 0.9941691160202026]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "conf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "f,ax = plt.subplots(1, 1)\n",
    "\n",
    "sns.heatmap(conf,square=True, annot=True, cbar=False,fmt='d',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       187\n",
      "           1       0.99      1.00      0.99       156\n",
      "\n",
      "    accuracy                           0.99       343\n",
      "   macro avg       0.99      0.99      0.99       343\n",
      "weighted avg       0.99      0.99      0.99       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}